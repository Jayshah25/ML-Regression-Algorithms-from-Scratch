{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multipleLinearRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF47DSPemrnX"
      },
      "source": [
        "# ML Regression Algorithms from Scratch - Multiple Linear Regression "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGjv_UdtP999"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klk23LsZQC0M"
      },
      "source": [
        "In this notebook, first, we implement Multiple Linear Regression from Scratch using Numpy without Sklearn. After the scratch implementation, we also implement the Multiple Linear Regression using Sklearn and compare the two models. The complete code is written and executed in Google Colab. No need of installing any additional packages is required. Download this notebook and upload to Google Colab to run it by yourself. Don't forget to grab your Datasets! \r\n",
        "\r\n",
        "The Dataset used here is the **50_Startups** dataset provided by the Super Data Science Team under their programme **Machine Learning A-Z: Hands on Python & R in Data Science**. Find the various datasets provided by them [here](https://www.superdatascience.com/pages/machine-learning).\r\n",
        "\r\n",
        "**Response Variable** : R&D Spend, Administration, Marketing Spend, State\r\n",
        "\r\n",
        "**Target Variable** : Profit\r\n",
        "\r\n",
        "**Equation Used** : y = W0 * X0 + W1 * X1 + W2 * X2 + .... + WN * XN\r\n",
        "\r\n",
        "**For Scratch Implementation:**\r\n",
        "    \r\n",
        "    Loss Function : Mean Squared Error\r\n",
        "\r\n",
        "    Optimization Algorithm : SGD\r\n",
        "\r\n",
        "    Weight Initialization : Xavier Initialization\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saI5S98Fkvx8"
      },
      "source": [
        "## Multiple Linear Regression from Scratch without SKlearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXvL5a1RlAzE"
      },
      "source": [
        "### Importing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXI1413Foust"
      },
      "source": [
        "#importing the required packages\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-N2v41Hfqdw"
      },
      "source": [
        "!cp /content/drive/MyDrive/50_Startups.csv /content"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0J-6GLhlFxE"
      },
      "source": [
        "### Get the Data and Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr3QiE8Jf3Pa"
      },
      "source": [
        "#Get the dataset\r\n",
        "dataset = pd.read_csv(r'/content/50_Startups.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "y8hHhyM1BuIb",
        "outputId": "e5d38506-f456-40fd-dd2c-08f11b394168"
      },
      "source": [
        "#Get a glimpse of the Dataset\r\n",
        "dataset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>192261.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>California</td>\n",
              "      <td>191792.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>Florida</td>\n",
              "      <td>191050.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>New York</td>\n",
              "      <td>182901.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>Florida</td>\n",
              "      <td>166187.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
              "0  165349.20       136897.80        471784.10    New York  192261.83\n",
              "1  162597.70       151377.59        443898.53  California  191792.06\n",
              "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
              "3  144372.41       118671.85        383199.62    New York  182901.99\n",
              "4  142107.34        91391.77        366168.42     Florida  166187.94"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ake97iPi8_I7"
      },
      "source": [
        "#Separating the independent and dependent features\r\n",
        "#Dependent features\r\n",
        "y = np.asarray(dataset['Profit'].values.tolist()) \r\n",
        "\r\n",
        "# Independent Features\r\n",
        "# Now, our dataset has only independent features\r\n",
        "dataset.drop([\"Profit\"], axis = 1, inplace = True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyX-0Xer146p"
      },
      "source": [
        "#### Handling the Categorical Variable \"**State**\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECD9PxPkzPnr",
        "outputId": "b83fe249-f51b-4e58-882e-94bce5c8024c"
      },
      "source": [
        "# Handling the Categorical Variable \"State\" with the One Hot Encoding Technique\r\n",
        "# There are many ways of handling categorical variables, One Hot Encosing is one of them\r\n",
        "# First, we get the counts of each value that the feature \"State\" can take\r\n",
        "dataset.iloc[:,3].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "California    17\n",
              "New York      17\n",
              "Florida       16\n",
              "Name: State, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lO5-yBG_2flQ",
        "outputId": "bb65e46f-6dce-4583-e0bb-c62b9075af3f"
      },
      "source": [
        "# Performing Label Encoding\r\n",
        "# Replacing California by 1, New York by 2, Florida by 3\r\n",
        "dataset.replace(to_replace=[\"California\",\"New York\", \"Florida\"], value=[1,2,3])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>131876.90</td>\n",
              "      <td>99814.71</td>\n",
              "      <td>362861.36</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>134615.46</td>\n",
              "      <td>147198.87</td>\n",
              "      <td>127716.82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>130298.13</td>\n",
              "      <td>145530.06</td>\n",
              "      <td>323876.68</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>120542.52</td>\n",
              "      <td>148718.95</td>\n",
              "      <td>311613.29</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>123334.88</td>\n",
              "      <td>108679.17</td>\n",
              "      <td>304981.62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>101913.08</td>\n",
              "      <td>110594.11</td>\n",
              "      <td>229160.95</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>100671.96</td>\n",
              "      <td>91790.61</td>\n",
              "      <td>249744.55</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>93863.75</td>\n",
              "      <td>127320.38</td>\n",
              "      <td>249839.44</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>91992.39</td>\n",
              "      <td>135495.07</td>\n",
              "      <td>252664.93</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>119943.24</td>\n",
              "      <td>156547.42</td>\n",
              "      <td>256512.92</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>114523.61</td>\n",
              "      <td>122616.84</td>\n",
              "      <td>261776.23</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>78013.11</td>\n",
              "      <td>121597.55</td>\n",
              "      <td>264346.06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>94657.16</td>\n",
              "      <td>145077.58</td>\n",
              "      <td>282574.31</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>91749.16</td>\n",
              "      <td>114175.79</td>\n",
              "      <td>294919.57</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>86419.70</td>\n",
              "      <td>153514.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>76253.86</td>\n",
              "      <td>113867.30</td>\n",
              "      <td>298664.47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>78389.47</td>\n",
              "      <td>153773.43</td>\n",
              "      <td>299737.29</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>73994.56</td>\n",
              "      <td>122782.75</td>\n",
              "      <td>303319.26</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>67532.53</td>\n",
              "      <td>105751.03</td>\n",
              "      <td>304768.73</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>77044.01</td>\n",
              "      <td>99281.34</td>\n",
              "      <td>140574.81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>64664.71</td>\n",
              "      <td>139553.16</td>\n",
              "      <td>137962.62</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>75328.87</td>\n",
              "      <td>144135.98</td>\n",
              "      <td>134050.07</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>72107.60</td>\n",
              "      <td>127864.55</td>\n",
              "      <td>353183.81</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>66051.52</td>\n",
              "      <td>182645.56</td>\n",
              "      <td>118148.20</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>65605.48</td>\n",
              "      <td>153032.06</td>\n",
              "      <td>107138.38</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>61994.48</td>\n",
              "      <td>115641.28</td>\n",
              "      <td>91131.24</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>61136.38</td>\n",
              "      <td>152701.92</td>\n",
              "      <td>88218.23</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>63408.86</td>\n",
              "      <td>129219.61</td>\n",
              "      <td>46085.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>55493.95</td>\n",
              "      <td>103057.49</td>\n",
              "      <td>214634.81</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>46426.07</td>\n",
              "      <td>157693.92</td>\n",
              "      <td>210797.67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>46014.02</td>\n",
              "      <td>85047.44</td>\n",
              "      <td>205517.64</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>28663.76</td>\n",
              "      <td>127056.21</td>\n",
              "      <td>201126.82</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>44069.95</td>\n",
              "      <td>51283.14</td>\n",
              "      <td>197029.42</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>20229.59</td>\n",
              "      <td>65947.93</td>\n",
              "      <td>185265.10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>38558.51</td>\n",
              "      <td>82982.09</td>\n",
              "      <td>174999.30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>28754.33</td>\n",
              "      <td>118546.05</td>\n",
              "      <td>172795.67</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>27892.92</td>\n",
              "      <td>84710.77</td>\n",
              "      <td>164470.71</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>23640.93</td>\n",
              "      <td>96189.63</td>\n",
              "      <td>148001.11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>15505.73</td>\n",
              "      <td>127382.30</td>\n",
              "      <td>35534.17</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>22177.74</td>\n",
              "      <td>154806.14</td>\n",
              "      <td>28334.72</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1000.23</td>\n",
              "      <td>124153.04</td>\n",
              "      <td>1903.93</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1315.46</td>\n",
              "      <td>115816.21</td>\n",
              "      <td>297114.46</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.00</td>\n",
              "      <td>135426.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>542.05</td>\n",
              "      <td>51743.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.00</td>\n",
              "      <td>116983.80</td>\n",
              "      <td>45173.06</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    R&D Spend  Administration  Marketing Spend  State\n",
              "0   165349.20       136897.80        471784.10      2\n",
              "1   162597.70       151377.59        443898.53      1\n",
              "2   153441.51       101145.55        407934.54      3\n",
              "3   144372.41       118671.85        383199.62      2\n",
              "4   142107.34        91391.77        366168.42      3\n",
              "5   131876.90        99814.71        362861.36      2\n",
              "6   134615.46       147198.87        127716.82      1\n",
              "7   130298.13       145530.06        323876.68      3\n",
              "8   120542.52       148718.95        311613.29      2\n",
              "9   123334.88       108679.17        304981.62      1\n",
              "10  101913.08       110594.11        229160.95      3\n",
              "11  100671.96        91790.61        249744.55      1\n",
              "12   93863.75       127320.38        249839.44      3\n",
              "13   91992.39       135495.07        252664.93      1\n",
              "14  119943.24       156547.42        256512.92      3\n",
              "15  114523.61       122616.84        261776.23      2\n",
              "16   78013.11       121597.55        264346.06      1\n",
              "17   94657.16       145077.58        282574.31      2\n",
              "18   91749.16       114175.79        294919.57      3\n",
              "19   86419.70       153514.11             0.00      2\n",
              "20   76253.86       113867.30        298664.47      1\n",
              "21   78389.47       153773.43        299737.29      2\n",
              "22   73994.56       122782.75        303319.26      3\n",
              "23   67532.53       105751.03        304768.73      3\n",
              "24   77044.01        99281.34        140574.81      2\n",
              "25   64664.71       139553.16        137962.62      1\n",
              "26   75328.87       144135.98        134050.07      3\n",
              "27   72107.60       127864.55        353183.81      2\n",
              "28   66051.52       182645.56        118148.20      3\n",
              "29   65605.48       153032.06        107138.38      2\n",
              "30   61994.48       115641.28         91131.24      3\n",
              "31   61136.38       152701.92         88218.23      2\n",
              "32   63408.86       129219.61         46085.25      1\n",
              "33   55493.95       103057.49        214634.81      3\n",
              "34   46426.07       157693.92        210797.67      1\n",
              "35   46014.02        85047.44        205517.64      2\n",
              "36   28663.76       127056.21        201126.82      3\n",
              "37   44069.95        51283.14        197029.42      1\n",
              "38   20229.59        65947.93        185265.10      2\n",
              "39   38558.51        82982.09        174999.30      1\n",
              "40   28754.33       118546.05        172795.67      1\n",
              "41   27892.92        84710.77        164470.71      3\n",
              "42   23640.93        96189.63        148001.11      1\n",
              "43   15505.73       127382.30         35534.17      2\n",
              "44   22177.74       154806.14         28334.72      1\n",
              "45    1000.23       124153.04          1903.93      2\n",
              "46    1315.46       115816.21        297114.46      3\n",
              "47       0.00       135426.92             0.00      1\n",
              "48     542.05        51743.15             0.00      2\n",
              "49       0.00       116983.80         45173.06      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvxlZ8ic4CoE"
      },
      "source": [
        "# There is no hierarchy relation between the labels\r\n",
        "# i.e label 3 does not have more importance than label 1\r\n",
        "# To handle this, we create 3 columns with the respective US State names\r\n",
        "dataset[\"California\"] = dataset.iloc[:, 3]\r\n",
        "dataset[\"New York\"] = dataset.iloc[:,3]\r\n",
        "dataset[\"Florida\"] = dataset.iloc[:,3]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "G9p2cAsL7NzT",
        "outputId": "d0d93c93-c9a9-44fc-b858-33eb9fc75346"
      },
      "source": [
        "#Let's have a look at the dataset now \r\n",
        "dataset.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "      <th>California</th>\n",
              "      <th>New York</th>\n",
              "      <th>Florida</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>New York</td>\n",
              "      <td>New York</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>California</td>\n",
              "      <td>California</td>\n",
              "      <td>California</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>Florida</td>\n",
              "      <td>Florida</td>\n",
              "      <td>Florida</td>\n",
              "      <td>Florida</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>New York</td>\n",
              "      <td>New York</td>\n",
              "      <td>New York</td>\n",
              "      <td>New York</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>Florida</td>\n",
              "      <td>Florida</td>\n",
              "      <td>Florida</td>\n",
              "      <td>Florida</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   R&D Spend  Administration  ...    New York     Florida\n",
              "0  165349.20       136897.80  ...    New York    New York\n",
              "1  162597.70       151377.59  ...  California  California\n",
              "2  153441.51       101145.55  ...     Florida     Florida\n",
              "3  144372.41       118671.85  ...    New York    New York\n",
              "4  142107.34        91391.77  ...     Florida     Florida\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3WmYcqr7_6q"
      },
      "source": [
        "Now, we replace the values of the particular US State of the particular US State Column by one and others by zero. This means, in the column California, we will replace all the California Values by 1 and the values New York, Florida by zero. This is called **One Hot Encoding**. We do this for each of the three columns. After this, we can drop our original column \"State\".\r\n",
        "\r\n",
        "Also, note that to avoid \"**Dummy Variable Trap**\", we need to drop one of the three US State columns. Basically, Linear Regression has an assumption that all the Independent Variables(X), in the equation **y = W0 * X0 + W1 * X1 + W2 * X2 + ... WN * XN**, are independent of each other. If we don't drop one of the three columns, we violate this assumption."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81TtFfZA7sWx"
      },
      "source": [
        "# Performing One Hot Encoding for the column \"California\"\r\n",
        "dataset.loc[dataset[\"California\"]!=\"California\", \"California\"] = 0\r\n",
        "dataset.loc[dataset[\"California\"]==\"California\", \"California\"] = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Eyj2ZaBQsr"
      },
      "source": [
        "# Performing One Hot Encoding for the column \"New York\"\r\n",
        "dataset.loc[dataset[\"New York\"]!=\"New York\", \"New York\"] = 0\r\n",
        "dataset.loc[dataset[\"New York\"]==\"New York\", \"New York\"] = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHduHIL2BmFl"
      },
      "source": [
        "# Performing One Hot Encoding for the column \"Florida\"\r\n",
        "dataset.loc[dataset.Florida!=\"Florida\", \"Florida\"] = 0\r\n",
        "dataset.loc[dataset.Florida==\"Florida\", \"Florida\"] = 1"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "s9dBevm9CJti",
        "outputId": "dd142924-9afe-4fbb-b3ff-aa8d6bad4e63"
      },
      "source": [
        "#Let's have a look at the Data\r\n",
        "dataset.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "      <th>California</th>\n",
              "      <th>New York</th>\n",
              "      <th>Florida</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>California</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>Florida</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>New York</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>Florida</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   R&D Spend  Administration  Marketing Spend  ... California New York Florida\n",
              "0  165349.20       136897.80        471784.10  ...          0        1       0\n",
              "1  162597.70       151377.59        443898.53  ...          1        0       0\n",
              "2  153441.51       101145.55        407934.54  ...          0        0       1\n",
              "3  144372.41       118671.85        383199.62  ...          0        1       0\n",
              "4  142107.34        91391.77        366168.42  ...          0        0       1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGAVV5aaDaQa"
      },
      "source": [
        "By looking at the US State columns and the \"State\" column, we can clearly see that we have successfully performed one hot encoding. Now, it's time to drop the \"State\" column and one of the three State columns. We will drop the column \"Florida\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LXRtoeoD6M6"
      },
      "source": [
        "# Dropping the columns\r\n",
        "dataset.drop([\"State\",\"Florida\"], axis = 1, inplace = True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "5g90psxJEaoJ",
        "outputId": "c11a51a7-b004-4caf-b030-39dc00a547b0"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>California</th>\n",
              "      <th>New York</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   R&D Spend  Administration  Marketing Spend California New York\n",
              "0  165349.20       136897.80        471784.10          0        1\n",
              "1  162597.70       151377.59        443898.53          1        0\n",
              "2  153441.51       101145.55        407934.54          0        0\n",
              "3  144372.41       118671.85        383199.62          0        1\n",
              "4  142107.34        91391.77        366168.42          0        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v1rXbyQEi4s"
      },
      "source": [
        "### Data Preprocessing Continued"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK6Yxe3zin8N"
      },
      "source": [
        "# Get the processed Independent features \r\n",
        "X = np.asarray(dataset.values.tolist())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaSyDT_fGlf5",
        "outputId": "cbed548a-2037-4948-c6f4-5673b3a188a7"
      },
      "source": [
        "#Get the shapes of X and y\r\n",
        "print(\"The shape of the independent fatures are \",X.shape)\r\n",
        "print(\"The shape of the dependent fatures are \",y.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of the independent fatures are  (50, 5)\n",
            "The shape of the dependent fatures are  (50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZhxeXCPi8Rd"
      },
      "source": [
        "#Reshaping the Dependent features\r\n",
        "y = y.reshape(len(y),1) # Changing the shape from (50,) to (50,1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FQ-HVLwSW0D"
      },
      "source": [
        "#Feature Scaling for Independent Variables\r\n",
        "for i in range(X.shape[1]-2):\r\n",
        "  X[:,i] = (X[:,i] - int(np.mean(X[:,i])))/np.std(X[:,i])\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtEFovnOu1x-"
      },
      "source": [
        "#Feature Scaling for Dependent Variables\r\n",
        "y = (y - int(np.mean(y)))/np.std(y)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHGaikOGkSYQ"
      },
      "source": [
        "#Adding the feature X0 = 1, so we have the equation: y =  (W1 * X1) + (W0 * X0) \r\n",
        "X = np.concatenate((X,np.ones((50,1))), axis = 1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNkI1FZ9US_f",
        "outputId": "f477b189-3ec0-4951-ede8-6383e448b898"
      },
      "source": [
        "X"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.01642504e+00,  5.60775975e-01,  2.15394390e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.95587388e+00,  1.08282964e+00,  1.92360120e+00,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.75437728e+00, -7.28233968e-01,  1.62652848e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.55479724e+00, -9.63415706e-02,  1.42221104e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.50495075e+00, -1.07989629e+00,  1.28152852e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.27981356e+00, -7.76216010e-01,  1.25421127e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.34007995e+00,  9.32170269e-01, -6.88149122e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.24507020e+00,  8.72003071e-01,  9.32186786e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.03038241e+00,  9.86975162e-01,  8.30887717e-01,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.09183275e+00, -4.56617186e-01,  7.76108248e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 6.20411795e-01, -3.87576029e-01,  1.49808075e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 5.93098965e-01, -1.06551653e+00,  3.19834431e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 4.43273419e-01,  2.15472124e-01,  3.20618249e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 4.02091150e-01,  5.10202013e-01,  3.43957596e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.01719429e+00,  1.26922245e+00,  3.75743081e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 8.97926670e-01,  4.58909136e-02,  4.19219510e-01,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 9.44547430e-02,  9.14147979e-03,  4.40447032e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 4.60733675e-01,  8.55689379e-01,  5.91017531e-01,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 3.96738485e-01, -2.58442307e-01,  6.92992870e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 2.79455197e-01,  1.15985963e+00, -1.74312617e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 5.57396340e-02, -2.69564591e-01,  7.23926803e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 1.02737147e-01,  1.16920915e+00,  7.32788599e-01,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [ 6.02012518e-03,  5.18726249e-02,  7.62376684e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.36187177e-01, -5.62188208e-01,  7.74349716e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 7.31281480e-02, -7.95446107e-01, -5.81938489e-01,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-1.99298141e-01,  6.56512199e-01, -6.03515917e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [ 3.53837501e-02,  8.21740976e-01, -6.35834687e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-3.55054466e-02,  2.35091603e-01,  1.17427197e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-1.68779170e-01,  2.21016356e+00, -7.67188629e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.78594993e-01,  1.14247983e+00, -8.58132855e-01,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-2.58060822e-01, -2.05605599e-01, -9.90356358e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-2.76944684e-01,  1.13057697e+00, -1.01441864e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-2.26935128e-01,  2.83946873e-01, -1.36244897e+00,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-4.01115378e-01, -6.59300973e-01,  2.98180513e-02,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-6.00668575e-01,  1.31055831e+00, -1.87781008e-03,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-6.09736394e-01, -1.30863447e+00, -4.54923508e-02,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-9.91556606e-01,  2.05947751e-01, -8.17617655e-02,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-6.52518763e-01, -2.52597096e+00, -1.15607448e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.17716400e+00, -1.99724731e+00, -2.12784058e-01,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-7.73806812e-01, -1.38309850e+00, -2.97582468e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-9.89563468e-01, -1.00877158e-01, -3.15785075e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.00852017e+00, -1.32077275e+00, -3.84551599e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.10209201e+00, -9.06914474e-01, -5.20595152e-01,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.28112009e+00,  2.17704585e-01, -1.44960388e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-1.13429185e+00,  1.20644242e+00, -1.50907337e+00,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.60033681e+00,  1.01276996e-01, -1.72739917e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-1.59339967e+00, -1.99298681e-01,  7.11123282e-01,\n",
              "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.62234847e+00,  5.07744936e-01, -1.74312617e+00,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00],\n",
              "       [-1.61041980e+00, -2.50938578e+00, -1.74312617e+00,\n",
              "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00],\n",
              "       [-1.62234847e+00, -1.57202446e-01, -1.36998392e+00,\n",
              "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_A9RqEVvGbU",
        "outputId": "5023ddc0-6cfe-4a99-ab4c-f470b398156c"
      },
      "source": [
        "y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.01121935],\n",
              "       [ 1.99944599],\n",
              "       [ 1.98085827],\n",
              "       [ 1.77664326],\n",
              "       [ 1.35775614],\n",
              "       [ 1.12726565],\n",
              "       [ 1.10549657],\n",
              "       [ 1.09622589],\n",
              "       [ 1.00748569],\n",
              "       [ 0.94603849],\n",
              "       [ 0.85486277],\n",
              "       [ 0.80818358],\n",
              "       [ 0.74117086],\n",
              "       [ 0.55876554],\n",
              "       [ 0.51604239],\n",
              "       [ 0.44873569],\n",
              "       [ 0.37545172],\n",
              "       [ 0.33478716],\n",
              "       [ 0.30713202],\n",
              "       [ 0.26978867],\n",
              "       [ 0.16195124],\n",
              "       [-0.01751782],\n",
              "       [-0.04159662],\n",
              "       [-0.08215341],\n",
              "       [-0.08671344],\n",
              "       [-0.11547707],\n",
              "       [-0.15735062],\n",
              "       [-0.17552631],\n",
              "       [-0.21878153],\n",
              "       [-0.2758662 ],\n",
              "       [-0.30260858],\n",
              "       [-0.36411142],\n",
              "       [-0.36550788],\n",
              "       [-0.38177109],\n",
              "       [-0.38342819],\n",
              "       [-0.3892749 ],\n",
              "       [-0.53391559],\n",
              "       [-0.55293888],\n",
              "       [-0.77148132],\n",
              "       [-0.77707766],\n",
              "       [-0.84639533],\n",
              "       [-0.85744966],\n",
              "       [-1.01534864],\n",
              "       [-1.05894419],\n",
              "       [-1.17319297],\n",
              "       [-1.18006622],\n",
              "       [-1.5669061 ],\n",
              "       [-1.74061116],\n",
              "       [-1.91319595],\n",
              "       [-2.43929721]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOc0wC0_uUV4"
      },
      "source": [
        "#Let's create a DataFrame \"Independent_Variables\" to visualize our final independent features\r\n",
        "Indpendent_Variables = pd.DataFrame(X)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bsqQyb4wvstF",
        "outputId": "0c5504a1-4b8b-48fe-86bc-9eaf5e27502e"
      },
      "source": [
        "Indpendent_Variables"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.016425</td>\n",
              "      <td>0.560776</td>\n",
              "      <td>2.153944</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.955874</td>\n",
              "      <td>1.082830</td>\n",
              "      <td>1.923601</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.754377</td>\n",
              "      <td>-0.728234</td>\n",
              "      <td>1.626528</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.554797</td>\n",
              "      <td>-0.096342</td>\n",
              "      <td>1.422211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.504951</td>\n",
              "      <td>-1.079896</td>\n",
              "      <td>1.281529</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.279814</td>\n",
              "      <td>-0.776216</td>\n",
              "      <td>1.254211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1.340080</td>\n",
              "      <td>0.932170</td>\n",
              "      <td>-0.688149</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.245070</td>\n",
              "      <td>0.872003</td>\n",
              "      <td>0.932187</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.030382</td>\n",
              "      <td>0.986975</td>\n",
              "      <td>0.830888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.091833</td>\n",
              "      <td>-0.456617</td>\n",
              "      <td>0.776108</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.620412</td>\n",
              "      <td>-0.387576</td>\n",
              "      <td>0.149808</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.593099</td>\n",
              "      <td>-1.065517</td>\n",
              "      <td>0.319834</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.443273</td>\n",
              "      <td>0.215472</td>\n",
              "      <td>0.320618</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.402091</td>\n",
              "      <td>0.510202</td>\n",
              "      <td>0.343958</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.017194</td>\n",
              "      <td>1.269222</td>\n",
              "      <td>0.375743</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.897927</td>\n",
              "      <td>0.045891</td>\n",
              "      <td>0.419220</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.094455</td>\n",
              "      <td>0.009141</td>\n",
              "      <td>0.440447</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.460734</td>\n",
              "      <td>0.855689</td>\n",
              "      <td>0.591018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.396738</td>\n",
              "      <td>-0.258442</td>\n",
              "      <td>0.692993</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.279455</td>\n",
              "      <td>1.159860</td>\n",
              "      <td>-1.743126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.055740</td>\n",
              "      <td>-0.269565</td>\n",
              "      <td>0.723927</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.102737</td>\n",
              "      <td>1.169209</td>\n",
              "      <td>0.732789</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.006020</td>\n",
              "      <td>0.051873</td>\n",
              "      <td>0.762377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-0.136187</td>\n",
              "      <td>-0.562188</td>\n",
              "      <td>0.774350</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.073128</td>\n",
              "      <td>-0.795446</td>\n",
              "      <td>-0.581938</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>-0.199298</td>\n",
              "      <td>0.656512</td>\n",
              "      <td>-0.603516</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.035384</td>\n",
              "      <td>0.821741</td>\n",
              "      <td>-0.635835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>-0.035505</td>\n",
              "      <td>0.235092</td>\n",
              "      <td>1.174272</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>-0.168779</td>\n",
              "      <td>2.210164</td>\n",
              "      <td>-0.767189</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>-0.178595</td>\n",
              "      <td>1.142480</td>\n",
              "      <td>-0.858133</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>-0.258061</td>\n",
              "      <td>-0.205606</td>\n",
              "      <td>-0.990356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>-0.276945</td>\n",
              "      <td>1.130577</td>\n",
              "      <td>-1.014419</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>-0.226935</td>\n",
              "      <td>0.283947</td>\n",
              "      <td>-1.362449</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>-0.401115</td>\n",
              "      <td>-0.659301</td>\n",
              "      <td>0.029818</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>-0.600669</td>\n",
              "      <td>1.310558</td>\n",
              "      <td>-0.001878</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>-0.609736</td>\n",
              "      <td>-1.308634</td>\n",
              "      <td>-0.045492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>-0.991557</td>\n",
              "      <td>0.205948</td>\n",
              "      <td>-0.081762</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>-0.652519</td>\n",
              "      <td>-2.525971</td>\n",
              "      <td>-0.115607</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>-1.177164</td>\n",
              "      <td>-1.997247</td>\n",
              "      <td>-0.212784</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>-0.773807</td>\n",
              "      <td>-1.383099</td>\n",
              "      <td>-0.297582</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>-0.989563</td>\n",
              "      <td>-0.100877</td>\n",
              "      <td>-0.315785</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>-1.008520</td>\n",
              "      <td>-1.320773</td>\n",
              "      <td>-0.384552</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>-1.102092</td>\n",
              "      <td>-0.906914</td>\n",
              "      <td>-0.520595</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>-1.281120</td>\n",
              "      <td>0.217705</td>\n",
              "      <td>-1.449604</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>-1.134292</td>\n",
              "      <td>1.206442</td>\n",
              "      <td>-1.509073</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>-1.600337</td>\n",
              "      <td>0.101277</td>\n",
              "      <td>-1.727399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>-1.593400</td>\n",
              "      <td>-0.199299</td>\n",
              "      <td>0.711123</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>-1.622348</td>\n",
              "      <td>0.507745</td>\n",
              "      <td>-1.743126</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>-1.610420</td>\n",
              "      <td>-2.509386</td>\n",
              "      <td>-1.743126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>-1.622348</td>\n",
              "      <td>-0.157202</td>\n",
              "      <td>-1.369984</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2    3    4    5\n",
              "0   2.016425  0.560776  2.153944  0.0  1.0  1.0\n",
              "1   1.955874  1.082830  1.923601  1.0  0.0  1.0\n",
              "2   1.754377 -0.728234  1.626528  0.0  0.0  1.0\n",
              "3   1.554797 -0.096342  1.422211  0.0  1.0  1.0\n",
              "4   1.504951 -1.079896  1.281529  0.0  0.0  1.0\n",
              "5   1.279814 -0.776216  1.254211  0.0  1.0  1.0\n",
              "6   1.340080  0.932170 -0.688149  1.0  0.0  1.0\n",
              "7   1.245070  0.872003  0.932187  0.0  0.0  1.0\n",
              "8   1.030382  0.986975  0.830888  0.0  1.0  1.0\n",
              "9   1.091833 -0.456617  0.776108  1.0  0.0  1.0\n",
              "10  0.620412 -0.387576  0.149808  0.0  0.0  1.0\n",
              "11  0.593099 -1.065517  0.319834  1.0  0.0  1.0\n",
              "12  0.443273  0.215472  0.320618  0.0  0.0  1.0\n",
              "13  0.402091  0.510202  0.343958  1.0  0.0  1.0\n",
              "14  1.017194  1.269222  0.375743  0.0  0.0  1.0\n",
              "15  0.897927  0.045891  0.419220  0.0  1.0  1.0\n",
              "16  0.094455  0.009141  0.440447  1.0  0.0  1.0\n",
              "17  0.460734  0.855689  0.591018  0.0  1.0  1.0\n",
              "18  0.396738 -0.258442  0.692993  0.0  0.0  1.0\n",
              "19  0.279455  1.159860 -1.743126  0.0  1.0  1.0\n",
              "20  0.055740 -0.269565  0.723927  1.0  0.0  1.0\n",
              "21  0.102737  1.169209  0.732789  0.0  1.0  1.0\n",
              "22  0.006020  0.051873  0.762377  0.0  0.0  1.0\n",
              "23 -0.136187 -0.562188  0.774350  0.0  0.0  1.0\n",
              "24  0.073128 -0.795446 -0.581938  0.0  1.0  1.0\n",
              "25 -0.199298  0.656512 -0.603516  1.0  0.0  1.0\n",
              "26  0.035384  0.821741 -0.635835  0.0  0.0  1.0\n",
              "27 -0.035505  0.235092  1.174272  0.0  1.0  1.0\n",
              "28 -0.168779  2.210164 -0.767189  0.0  0.0  1.0\n",
              "29 -0.178595  1.142480 -0.858133  0.0  1.0  1.0\n",
              "30 -0.258061 -0.205606 -0.990356  0.0  0.0  1.0\n",
              "31 -0.276945  1.130577 -1.014419  0.0  1.0  1.0\n",
              "32 -0.226935  0.283947 -1.362449  1.0  0.0  1.0\n",
              "33 -0.401115 -0.659301  0.029818  0.0  0.0  1.0\n",
              "34 -0.600669  1.310558 -0.001878  1.0  0.0  1.0\n",
              "35 -0.609736 -1.308634 -0.045492  0.0  1.0  1.0\n",
              "36 -0.991557  0.205948 -0.081762  0.0  0.0  1.0\n",
              "37 -0.652519 -2.525971 -0.115607  1.0  0.0  1.0\n",
              "38 -1.177164 -1.997247 -0.212784  0.0  1.0  1.0\n",
              "39 -0.773807 -1.383099 -0.297582  1.0  0.0  1.0\n",
              "40 -0.989563 -0.100877 -0.315785  1.0  0.0  1.0\n",
              "41 -1.008520 -1.320773 -0.384552  0.0  0.0  1.0\n",
              "42 -1.102092 -0.906914 -0.520595  1.0  0.0  1.0\n",
              "43 -1.281120  0.217705 -1.449604  0.0  1.0  1.0\n",
              "44 -1.134292  1.206442 -1.509073  1.0  0.0  1.0\n",
              "45 -1.600337  0.101277 -1.727399  0.0  1.0  1.0\n",
              "46 -1.593400 -0.199299  0.711123  0.0  0.0  1.0\n",
              "47 -1.622348  0.507745 -1.743126  1.0  0.0  1.0\n",
              "48 -1.610420 -2.509386 -1.743126  0.0  1.0  1.0\n",
              "49 -1.622348 -0.157202 -1.369984  1.0  0.0  1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEAUmgwclN5d"
      },
      "source": [
        "### Utility Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMFw3Ps4IjIY"
      },
      "source": [
        "# The method \"split_data\" splits the given dataset into trainset and testset\r\n",
        "# This is similar to the method \"train_test_split\" from \"sklearn.model_selection\"\r\n",
        "def split_data(X,y,test_size=0.2,random_state=0):\r\n",
        "    np.random.seed(random_state)                  #set the seed for reproducible results\r\n",
        "    indices = np.random.permutation(len(X))       #shuffling the indices\r\n",
        "    data_test_size = int(X.shape[0] * test_size)  #Get the test size\r\n",
        "\r\n",
        "    #Separating the Independent and Dependent features into the Train and Test Set\r\n",
        "    train_indices = indices[data_test_size:]\r\n",
        "    test_indices = indices[:data_test_size]\r\n",
        "    X_train = X[train_indices]\r\n",
        "    y_train = y[train_indices]\r\n",
        "    X_test = X[test_indices]\r\n",
        "    y_test = y[test_indices]\r\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjKljivClbWf"
      },
      "source": [
        "### Coding the LinearRegression Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBt41FyrunIl"
      },
      "source": [
        "class multipleLinearRegression():\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "    #No instance Variables required\r\n",
        "    pass\r\n",
        "\r\n",
        "  def forward(self,X,y,W):\r\n",
        "    \"\"\"\r\n",
        "    Parameters:\r\n",
        "    X (array) : Independent Features\r\n",
        "    y (array) : Dependent Features/ Target Variable\r\n",
        "    W (array) : Weights \r\n",
        "\r\n",
        "    Returns:\r\n",
        "    loss (float) : Calculated Sqaured Error Loss for y and y_pred\r\n",
        "    y_pred (array) : Predicted Target Variable\r\n",
        "    \"\"\"\r\n",
        "    y_pred = sum(W * X)\r\n",
        "    loss = ((y_pred-y)**2)/2    #Loss = Squared Error, we introduce 1/2 for ease in the calculation\r\n",
        "    return loss, y_pred\r\n",
        "\r\n",
        "  def updateWeights(self,X,y_pred,y_true,W,alpha,index):\r\n",
        "    \"\"\"\r\n",
        "    Parameters:\r\n",
        "    X (array) : Independent Features\r\n",
        "    y_pred (array) : Predicted Target Variable\r\n",
        "    y_true (array) : Dependent Features/ Target Variable\r\n",
        "    W (array) : Weights\r\n",
        "    alpha (float) : learning rate\r\n",
        "    index (int) : Index to fetch the corresponding values of W, X and y \r\n",
        "\r\n",
        "    Returns:\r\n",
        "    W (array) : Update Values of Weight\r\n",
        "    \"\"\"\r\n",
        "    for i in range(X.shape[1]):\r\n",
        "      #alpha = learning rate, rest of the RHS is derivative of loss function\r\n",
        "      W[i] -= (alpha * (y_pred-y_true[index])*X[index][i]) \r\n",
        "    return W\r\n",
        "\r\n",
        "  def train(self, X, y, epochs=10, alpha=0.001, random_state=0):\r\n",
        "    \"\"\"\r\n",
        "    Parameters:\r\n",
        "    X (array) : Independent Feature\r\n",
        "    y (array) : Dependent Features/ Target Variable\r\n",
        "    epochs (int) : Number of epochs for training, default value is 10\r\n",
        "    alpha (float) : learning rate, default value is 0.001\r\n",
        "\r\n",
        "    Returns:\r\n",
        "    y_pred (array) : Predicted Target Variable\r\n",
        "    loss (float) : Calculated Sqaured Error Loss for y and y_pred\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    num_rows = X.shape[0] #Number of Rows\r\n",
        "    num_cols = X.shape[1] #Number of Columns \r\n",
        "    W = np.random.randn(1,num_cols) / np.sqrt(num_rows) #Weight Initialization\r\n",
        "\r\n",
        "    #Calculating Loss and Updating Weights\r\n",
        "    train_loss = []\r\n",
        "    num_epochs = []\r\n",
        "    train_indices = [i for i in range(X.shape[0])]\r\n",
        "    for j in range(epochs):\r\n",
        "      cost=0\r\n",
        "      np.random.seed(random_state)\r\n",
        "      np.random.shuffle(train_indices)\r\n",
        "      for i in train_indices:\r\n",
        "        loss, y_pred = self.forward(X[i],y[i],W[0])\r\n",
        "        cost+=loss\r\n",
        "        W[0] = self.updateWeights(X,y_pred,y,W[0],alpha,i)\r\n",
        "      train_loss.append(cost)\r\n",
        "      num_epochs.append(j)\r\n",
        "    return W[0], train_loss, num_epochs\r\n",
        "\r\n",
        "  def test(self, X_test, y_test, W_trained):\r\n",
        "    \"\"\"\r\n",
        "    Parameters:\r\n",
        "    X_test (array) : Independent Features from the Test Set\r\n",
        "    y_test (array) : Dependent Features/ Target Variable from the Test Set\r\n",
        "    W_trained (array) : Trained Weights\r\n",
        "    test_indices (list) : Index to fetch the corresponding values of W_trained,\r\n",
        "                          X_test and y_test \r\n",
        "\r\n",
        "    Returns:\r\n",
        "    test_pred (list) : Predicted Target Variable\r\n",
        "    test_loss (list) : Calculated Sqaured Error Loss for y and y_pred\r\n",
        "    \"\"\"\r\n",
        "    test_pred = []\r\n",
        "    test_loss = []\r\n",
        "    test_indices = [i for i in range(X_test.shape[0])]\r\n",
        "    for i in test_indices:\r\n",
        "        loss, y_test_pred = self.forward(X_test[i], W_trained, y_test[i])\r\n",
        "        test_pred.append(y_test_pred)\r\n",
        "        test_loss.append(loss)\r\n",
        "    return test_pred, test_loss\r\n",
        "    \r\n",
        "\r\n",
        "  def predict(self, W_trained, X_sample):\r\n",
        "    prediction = sum(W_trained * X_sample)\r\n",
        "    return prediction\r\n",
        "\r\n",
        "  def plotLoss(self, loss, epochs):\r\n",
        "    \"\"\"\r\n",
        "    Parameters:\r\n",
        "    loss (list) : Calculated Sqaured Error Loss for y and y_pred\r\n",
        "    epochs (list): Number of Epochs\r\n",
        "\r\n",
        "    Returns: None\r\n",
        "    Plots a graph of Loss vs Epochs\r\n",
        "    \"\"\"\r\n",
        "    plt.plot(epochs, loss)\r\n",
        "    plt.xlabel('Number of Epochs')\r\n",
        "    plt.ylabel('Loss')\r\n",
        "    plt.title('Plot Loss')\r\n",
        "    plt.show()\r\n",
        "  \r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL3sFhd5sJ85"
      },
      "source": [
        "### Performing Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeUC0VYImNlQ"
      },
      "source": [
        "#Splitting the dataset\r\n",
        "X_train, y_train, X_test, y_test = split_data(X,y)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UU50V05mRoN"
      },
      "source": [
        "#declaring the \"regressor\" as an object of the class LinearRegression\r\n",
        "regressor = multipleLinearRegression()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wLjNkQnusqh"
      },
      "source": [
        "#Training \r\n",
        "W_trained, train_loss, num_epochs = regressor.train(X_train, y_train, epochs=200, alpha=0.0001)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JQSySiyxJ4n"
      },
      "source": [
        "#Testing on the Test Dataset\r\n",
        "test_pred, test_loss = regressor.test(X_test, y_test, W_trained)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbXBW88kpjmN"
      },
      "source": [
        "### Visualizing Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "z80Vq2Y0wZMa",
        "outputId": "26d5062a-38cf-401a-a85d-5e62432049b1"
      },
      "source": [
        "#Plot the Train Loss\r\n",
        "regressor.plotLoss(train_loss, num_epochs)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7qN5ze_nCaU"
      },
      "source": [
        "## Multople Linear Regression using Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qzeCvuHnUkd"
      },
      "source": [
        "### Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxTLPi00nPlR"
      },
      "source": [
        "import pandas\r\n",
        "import matplotlib.pyplot as plt \r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n4bZLnyoRBF"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RVobIAMoUJP"
      },
      "source": [
        "#Get the Dataset and separating the independent and dependent features\r\n",
        "dataset_sk = pd.read_csv('50_Startups.csv')\r\n",
        "X_sk = dataset_sk.iloc[:, :-1].values\r\n",
        "y_sk = dataset_sk.iloc[:, 4].values"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4q7r4id6CYL"
      },
      "source": [
        "# Performing One hot encoding using sklearn\r\n",
        "labelencoder_X_sk = LabelEncoder()\r\n",
        "X_sk[:,3] = labelencoder_X_sk.fit_transform(X_sk[:,3])\r\n",
        "\r\n",
        "onehotencoder = OneHotEncoder(handle_unknown='ignore')\r\n",
        "X_sk_categorical = onehotencoder.fit_transform(X_sk[:,3].reshape(-1,1)).toarray()\r\n",
        "X_sk = np.concatenate((X_sk,X_sk_categorical),axis=1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MKW8Hl88JBj"
      },
      "source": [
        "# Dropping the \"State\" and \"California\" columns\r\n",
        "X_sk = X_sk[:, [0,1,2,5,6]]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfpkKXFR7yWu",
        "outputId": "0aab6c8d-c240-4a42-ac56-454d5aae75c3"
      },
      "source": [
        "X_sk.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHBdiwMyo8c0"
      },
      "source": [
        "### Performing the Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2SAKXOUo07O"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\r\n",
        "X_train_sk, X_test_sk, y_train_sk, y_test_sk = train_test_split(X_sk, y_sk, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ZxKwyzpAuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd9e5a23-298e-4011-f99f-6f40a1bcf8b3"
      },
      "source": [
        "# Fitting Simple Linear Regression to the Training set\r\n",
        "regressor_sk = LinearRegression()\r\n",
        "regressor_sk.fit(X_train_sk, y_train_sk)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPHHkldApF7t"
      },
      "source": [
        "# Predicting the Test set results\r\n",
        "y_pred = regressor_sk.predict(X_test_sk)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF4BtcnoQbr2",
        "outputId": "a62a180d-7520-4d6f-99dc-a7ff1dc0452f"
      },
      "source": [
        "X_train_sk.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XtnJj4e2vCf"
      },
      "source": [
        "## Comparing the Performance of the Two Regressors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oEzqg7pQBsb",
        "outputId": "3b17987c-0deb-4f99-eaab-2797aad68023"
      },
      "source": [
        "#Making the Prediction using Sklearn Regression\r\n",
        "print(regressor_sk.predict([[160000,140000,5000000,1,0]]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[353003.60726928]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-4eO-Sz3iCu",
        "outputId": "fb594488-eb19-4363-da0b-0aee2a97d7a5"
      },
      "source": [
        "#Making a Prediction\r\n",
        "pred = regressor.predict(W_trained,[160000,140000,5000000,1,0,1])\r\n",
        "print(pred)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1465827.170108471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjbeIre6SYCz"
      },
      "source": [
        "The values used for Independent features resemble closely to the first set of features of our Dataset. Therefore, the prediction should be somewhere around 2,00,000. Therefore, SKlearn Regressor predicts better than our Naive Regressor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cdYj7q_eNl2"
      },
      "source": [
        "There can be various reasons behind these results like choice of loss function, Optimization Algorithm used, etc. However, the prime goal of this notebook was to demonstrate the implementation of Multiple Linear Regression and not to perform better than Sklearn. \r\n",
        "\r\n",
        "Definitely, you can download this notebook and change hyperparameters, Optimization Algorithm, etc. and start your ML Journey!\r\n",
        "\r\n",
        "**Best of Luck!**\r\n",
        "\r\n"
      ]
    }
  ]
}